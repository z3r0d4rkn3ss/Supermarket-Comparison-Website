from flask import Flask, jsonify
from apscheduler.schedulers.background import BackgroundScheduler
from scraper import scrape_asda, scrape_sainsburys, scrape_tesco, scrape_aldi, scrape_iceland, scrape_morrisons
from models import db, Product, Supermarket
from scraper.scraper import scrape_supermarket

# Create Flask app
app = Flask(__name__)

@app.route('/api/compare_prices', methods=['GET'])
def compare_prices():
    supermarkets = [
        'https://groceries.asda.com',
        'https://www.sainsburys.co.uk',
        'https://groceries.aldi.co.uk',
        'https://www.tesco.com/groceries',
        'https://www.iceland.co.uk',
        'https://groceries.morrisons.com/'
    ]
    
    # Scrape prices from all supermarkets and return the data
    scraped_data = []
    for url in supermarkets:
        soup = scrape_supermarket(url)
        # Process the data (parse and extract prices) and append to scraped_data
        if soup:
            # Example of extracting product info (this will depend on the website structure)
            scraped_data.append({'supermarket': url, 'product': 'example_product', 'price': 'example_price'})

    return jsonify(scraped_data)

# Load configuration and initialize the database
app.config.from_object('config.Config')
app.config['SQLALCHEMY_DATABASE_URI'] = 'postgresql://username:password@localhost/grocery_comparator'
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
db.init_app(app)

# Register API routes
app.register_blueprint(api_routes, url_prefix='/api')

# Create a background scheduler for periodic tasks
scheduler = BackgroundScheduler()

def daily_scrape():
    """
    This function will be triggered once a day to scrape all supermarkets.
    """
    print("Starting daily scrape...")

    # Scrape from all supermarkets
    products_asda = scrape_asda()
    products_sainsburys = scrape_sainsburys()
    products_tesco = scrape_tesco()
    products_aldi = scrape_aldi()
    products_iceland = scrape_iceland()
    products_morrisons = scrape_morrisons()

    # Insert/update products in the database
    for product_list, supermarket_name in zip(
        [products_asda, products_sainsburys, products_tesco, products_aldi, products_iceland, products_morrisons],
        ["ASDA", "Sainsbury's", "Tesco", "Aldi", "Iceland", "Morrisons"]
    ):
        supermarket = Supermarket.query.filter_by(name=supermarket_name).first()
        if supermarket is None:
            supermarket = Supermarket(name=supermarket_name, url=f"https://{supermarket_name.lower()}.com")
            db.session.add(supermarket)
        
        for product in product_list:
            # Check if product exists, update if necessary, else insert
            existing_product = Product.query.filter_by(name=product['name'], supermarket_id=supermarket.id).first()
            if existing_product:
                existing_product.price = product['price']
                existing_product.link = product['link']
            else:
                new_product = Product(
                    name=product['name'],
                    price=product['price'],
                    link=product['link'],
                    supermarket=supermarket
                )
                db.session.add(new_product)
    
    db.session.commit()
    print("Daily scrape completed.")

# Add the daily scrape task to the scheduler (runs every 24 hours)
scheduler.add_job(daily_scrape, 'interval', days=1, start_date='2024-12-29 00:00:00')

# Start the scheduler
scheduler.start()

@app.route('/compare', methods=['POST'])
def compare():
    data = request.get_json()
    shopping_list = data.get("shopping_list", [])

    results = []
    for item in shopping_list:
        # Find the cheapest price for each product
        product = Product.query.filter_by(name=item).order_by(Product.price).first()
        if product:
            results.append({
                "name": product.name,
                "price": product.price,
                "supermarket": product.supermarket.name,
                "link": product.link
            })
    
    return jsonify({"results": results})

if __name__ == '__main__':
    app.run(debug=True)
