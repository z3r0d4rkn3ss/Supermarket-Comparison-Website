from flask import Flask, jsonify
from apscheduler.schedulers.background import BackgroundScheduler
from scraper import scrape_asda, scrape_sainsburys, scrape_tesco, scrape_aldi, scrape_iceland, scrape_morrisons
from models import db, Product, Supermarket

# Create Flask app
app = Flask(__name__)

# Load configuration and initialize the database
app.config.from_object('config.Config')
db.init_app(app)

# Create a background scheduler for periodic tasks
scheduler = BackgroundScheduler()

def daily_scrape():
    """
    This function will be triggered once a day to scrape all supermarkets.
    """
    print("Starting daily scrape...")

    # Scrape from all supermarkets
    products_asda = scrape_asda()
    products_sainsburys = scrape_sainsburys()
    products_tesco = scrape_tesco()
    products_aldi = scrape_aldi()
    products_iceland = scrape_iceland()
    products_morrisons = scrape_morrisons()

    # Insert/update products in the database
    for product_list, supermarket_name in zip(
        [products_asda, products_sainsburys, products_tesco, products_aldi, products_iceland, products_morrisons],
        ["ASDA", "Sainsbury's", "Tesco", "Aldi", "Iceland", "Morrisons"]
    ):
        supermarket = Supermarket.query.filter_by(name=supermarket_name).first()
        if supermarket is None:
            supermarket = Supermarket(name=supermarket_name, url=f"https://{supermarket_name.lower()}.com")
            db.session.add(supermarket)
        
        for product in product_list:
            # Check if product exists, update if necessary, else insert
            existing_product = Product.query.filter_by(name=product['name'], supermarket_id=supermarket.id).first()
            if existing_product:
                existing_product.price = product['price']
                existing_product.link = product['link']
            else:
                new_product = Product(
                    name=product['name'],
                    price=product['price'],
                    link=product['link'],
                    supermarket=supermarket
                )
                db.session.add(new_product)
    
    db.session.commit()
    print("Daily scrape completed.")

# Add the daily scrape task to the scheduler (runs every 24 hours)
scheduler.add_job(daily_scrape, 'interval', days=1, start_date='2024-12-29 00:00:00')

# Start the scheduler
scheduler.start()

@app.route('/compare', methods=['POST'])
def compare():
    data = request.get_json()
    shopping_list = data.get("shopping_list", [])

    results = []
    for item in shopping_list:
        # Find the cheapest price for each product
        product = Product.query.filter_by(name=item).order_by(Product.price).first()
        if product:
            results.append({
                "name": product.name,
                "price": product.price,
                "supermarket": product.supermarket.name,
                "link": product.link
            })
    
    return jsonify({"results": results})

if __name__ == '__main__':
    app.run(debug=True)
